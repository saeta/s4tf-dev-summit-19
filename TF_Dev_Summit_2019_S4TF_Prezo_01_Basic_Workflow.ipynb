{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Dev Summit - 2019 - S4TF Prezo - 01 Basic Workflow",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%disableCompletion\n",
        "import TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuk5YqDAjI7k",
        "colab_type": "text"
      },
      "source": [
        "# Modifying machine learning models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWRtV0ujokr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Model: Layer {\n",
        "    var conv = Conv2D<Float>(filterShape: (5, 5, 3, 6))\n",
        "    var maxpool = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "    var flatten = Flatten<Float>()\n",
        "    var dense = Dense<Float>(inputSize: 36 * 6, outputSize: 10)\n",
        "\n",
        "    @differentiable\n",
        "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
        "        return input.sequenced(through: conv, maxpool, flatten, dense)\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O-5kCEniSpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// Use random training data.\n",
        "let x = Tensor<Float>(randomNormal: [10, 16, 16, 3])\n",
        "let y = Tensor<Int32>(rangeFrom: 0, to: 10, stride: 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x44kFjA0tRFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var model = Model()\n",
        "let opt = SGD(for: model)\n",
        "Context.local.learningPhase = .training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMxjNQIDtxgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in 1...10 {\n",
        "    print(\"Starting training step \\(i)\")\n",
        "    let (loss, grads) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "        let logits = model(x)\n",
        "        return softmaxCrossEntropy(logits: logits, labels: y)\n",
        "    }\n",
        "    print(\"Loss: \\(loss)\")\n",
        "    opt.update(&model, along: grads)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vswgu61hJVMd",
        "colab_type": "text"
      },
      "source": [
        "Now: modify the model to use skip connections!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj2p7hI9irot",
        "colab_type": "text"
      },
      "source": [
        "# Writing custom layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kkzkXoTIfaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// A custom layer type that's similar to a Dense layer, but with an extra bias\n",
        "// term.\n",
        "struct DoubleBiasDense: Layer {\n",
        "  // TODO(saeta): FILL ME IN!\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCPK6TGCmv6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Model2: Layer {\n",
        "    var conv = Conv2D<Float>(filterShape: (5, 5, 3, 6))\n",
        "    var maxpool = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "    var flatten = Flatten<Float>()\n",
        "    var dense = DoubleBiasDense(inputSize: 36 * 6, outputSize: 10)\n",
        "\n",
        "    @differentiable\n",
        "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
        "        return input.sequenced(through: conv, maxpool, flatten, dense)\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBHoMwoesa_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var model = Model2()\n",
        "let opt = SGD(for: model)\n",
        "\n",
        "for i in 1...10 {\n",
        "    print(\"Starting training step \\(i)\")\n",
        "    let (loss, grads) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "        let logits = model(x)\n",
        "        return softmaxCrossEntropy(logits: logits, label: y)\n",
        "    }\n",
        "    print(\"Loss: \\(loss)\")\n",
        "    opt.update(&model, along: grads)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-d3KMECJpwG",
        "colab_type": "text"
      },
      "source": [
        "VoilÃ .... almost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfqUcfPHjzLv",
        "colab_type": "text"
      },
      "source": [
        "# Experimenting with batch sizes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JliPTFbSDHS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in 1...10 {\n",
        "    print(\"Starting training step \\(i)\")\n",
        "    var grads = Model2.TangentVector.zero\n",
        "    for j in 1...4 {\n",
        "        print(\"Running substep \\(j)\")\n",
        "        let stepGrad = gradient(at: model) { model -> Tensor<Float> in\n",
        "            let logits = model(x)\n",
        "            return softmaxCrossEntropy(logits: logits, labels: y)\n",
        "        }\n",
        "        grads += stepGrad\n",
        "    }\n",
        "    opt.update(&model, along: grads)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv7BGxjkFb9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}